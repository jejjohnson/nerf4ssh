{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4123c4da-15c8-47f8-9781-7c14c94e2910",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Modulations\n",
    "<!-- ---\n",
    "title: Modulation\n",
    "date: 2023-04-01\n",
    "authors:\n",
    "  - name: J. Emmanuel Johnson\n",
    "    affiliations:\n",
    "      - MEOM Lab\n",
    "    roles:\n",
    "      - Primary Programmer\n",
    "    email: jemanjohnson34@gmail.com\n",
    "license: CC-BY-4.0\n",
    "keywords: NerFs, Images\n",
    "--- -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028f5f4-c74e-42aa-a147-be448542e2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import autoroot\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import equinox as eqx\n",
    "import kernex as kex\n",
    "import finitediffx as fdx\n",
    "import diffrax as dfx\n",
    "import xarray as xr\n",
    "import metpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from jaxtyping import Float, Array, PyTree, ArrayLike\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71086b9-24cb-4b1d-9eab-93ce21ac8d12",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Recap Formulation\n",
    "\n",
    "We are interested in learning non-linear functions $\\boldsymbol{f}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{f}(\\mathbf{x}) &=\n",
    "\\mathbf{w}^\\top\\boldsymbol{\\phi}(\\mathbf{x})+\\mathbf{b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the $\\boldsymbol{\\phi}(\\cdot)$ is a basis function. Neural Fields typically try to learn this basis funciton via a series of composite functions of the form\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}(\\mathbf{x}) =\n",
    "\\boldsymbol{\\phi}_L\\circ\\boldsymbol{\\phi}_{L-1}\n",
    "\\circ\\cdots\\circ\n",
    "\\boldsymbol{\\phi}_2\\circ\\boldsymbol{\\phi}_{1}(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9495206-f1e1-42d6-beba-13fe42d9253f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Problems\n",
    "\n",
    "Here, we will demonstrate a problem that a naive network has."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ac67435-b31d-4788-b79d-3d2e3b5ac1df",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefda25b-01ae-4654-b4ce-03c17732a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget wget -nc https://s3.us-east-1.wasabisys.com/melody/osse_data/ref/NATL60-CJM165_GULFSTREAM_ssh_y2013.1y.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de7073-939d-4ab9-a419-d5564a660681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde389d0-00ed-4b52-b577-f97c1231a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\n",
    "    \"/gpfswork/rech/cli/uvo53rl/projects/jejeqx/data/natl60/NATL60-CJM165_GULFSTREAM_ssh_y2013.1y.nc\"\n",
    ").is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d5566-74c1-484e-9469-e5b95ddd9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Subset:\n",
    "    _target_: str = \"builtins.slice\"\n",
    "    _args_: List = field(default_factory=lambda: [\"2013-01-01\", \"2013-01-01\"])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SSHDM:\n",
    "    _target_: str = \"jejeqx._src.datamodules.natl60.SSHNATL60\"\n",
    "    batch_size: int = 10_000\n",
    "    shuffle: bool = False\n",
    "    split_method: str = \"random\"\n",
    "    train_size: float = 0.85\n",
    "    coords: List = field(default_factory=lambda: [\"x\", \"y\", \"z\"])\n",
    "    variables: List = field(default_factory=lambda: [\"ssh\"])\n",
    "    coarsen: Dict = field(default_factory=lambda: {\"lon\": 2, \"lat\": 2})\n",
    "    directory: str = \"/gpfswork/rech/cli/uvo53rl/projects/jejeqx/data/natl60/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e67bf9-ba0a-488e-918d-cd745753a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from jejeqx._src.transforms.dataframe.spatial import Spherical2Cartesian\n",
    "from jejeqx._src.transforms.dataframe.temporal import TimeDelta\n",
    "from jejeqx._src.transforms.dataframe.scaling import MinMaxDF\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ebd53-2fab-41cb-a55d-fe849286bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial transform\n",
    "transforms = Pipeline(\n",
    "    [\n",
    "        (\"cartesian3d\", Spherical2Cartesian(radius=1.0, units=\"degrees\")),\n",
    "        (\"spatialminmax\", MinMaxDF([\"x\", \"y\", \"z\"], -1, 1)),\n",
    "        (\"timedelta\", TimeDelta(\"2012-10-01\", 1, \"s\")),\n",
    "        (\"timeminmax\", MinMaxDF([\"time\"], -1, 1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d46d3-df1d-433f-9467-86b6498b0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = {\"time\": slice(\"2013-01-01\", \"2013-01-01\")}\n",
    "\n",
    "config_dm = OmegaConf.structured(SSHDM())\n",
    "\n",
    "dm = hydra.utils.instantiate(config_dm, select=select, transforms=transforms)\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "\n",
    "init = dm.ds_train[:]\n",
    "x_init, y_init = init\n",
    "x_init.min(), x_init.max(), x_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ccd32f-9e10-4d25-863b-d42157052c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm.ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b82332-9fba-46b9-90ad-2aec698381c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_, _ = dm.ds_train[:]\n",
    "\n",
    "# fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# ax.scatter3D(init_[...,0], init_[..., 1], init_[..., 2])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e367177-80a4-4490-acdc-02d6a2932f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda = dm.load_xrdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5da277-9e83-4475-863c-d853d64710ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, figsize=(5, 4))\n",
    "\n",
    "xrda.ssh.isel(time=0).plot.pcolormesh(ax=ax, cmap=\"viridis\")\n",
    "ax.set(title=\"Original\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe6e21-9d7b-4e8b-87d8-a40f3995bfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ffb2f-decd-4b19-ad3a-ee264c1088df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 5e-3\n",
    "# num_epochs = 5_000\n",
    "# num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "# @dataclass\n",
    "# class FoxDataModule:\n",
    "#     _target_: str = \"jejeqx._src.datamodules.image.ImageFox\"\n",
    "#     batch_size: int = 10_000\n",
    "#     train_size: float = 0.5\n",
    "#     shuffle: bool = False\n",
    "#     split_method: str = \"even\"\n",
    "#     resize: int = 4\n",
    "\n",
    "# @dataclass\n",
    "# class Training:\n",
    "#     num_epochs: int = 2_000\n",
    "\n",
    "# @dataclass\n",
    "# class Model:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.siren.SirenNet\"\n",
    "#     in_size: int = 2\n",
    "#     out_size: int = 3\n",
    "#     width_size: int = 128\n",
    "#     depth: int = 5\n",
    "\n",
    "# @dataclass\n",
    "# class Optimizer:\n",
    "#     _target_: str = \"optax.adam\"\n",
    "#     learning_rate: float = lr\n",
    "\n",
    "# @dataclass\n",
    "# class Scheduler:\n",
    "#     _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "#     init_value: float = 0.0\n",
    "#     peak_value: float = lr\n",
    "#     warmup_steps: int = 100\n",
    "#     decay_steps: int = int(num_epochs * num_steps_per_epoch)\n",
    "#     end_value: float = 0.01 * lr\n",
    "\n",
    "# @dataclass\n",
    "# class Config:\n",
    "#     datamodule: FoxDataModule = FoxDataModule()\n",
    "#     model: Model = Model()\n",
    "#     optimizer: Optimizer = Optimizer()\n",
    "#     scheduler: Scheduler = Scheduler()\n",
    "#     num_epochs: int = 2_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc918a-caec-4696-9e70-1d101b62d0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import optax\n",
    "\n",
    "# config = Config()\n",
    "# config = OmegaConf.structured(Config())\n",
    "\n",
    "# # initialize datamodule\n",
    "# dm = hydra.utils.instantiate(config.datamodule)\n",
    "\n",
    "# dm.setup()\n",
    "\n",
    "\n",
    "# # initialize optimizer\n",
    "# optimizer = hydra.utils.instantiate(config.optimizer)\n",
    "\n",
    "# # initialize scheduler\n",
    "# num_steps_per_epoch = len(dm.ds_train)\n",
    "# decay_steps = int(num_steps_per_epoch * config.num_epochs)\n",
    "# schedule_fn = hydra.utils.instantiate(config.scheduler, decay_steps=decay_steps)\n",
    "\n",
    "# # initialize optimizer + scheduler\n",
    "# optimizer = optax.chain(optimizer, optax.scale_by_schedule(schedule_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7ad02-d923-4fca-b106-ce87652b9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibatch = next(iter(dm.train_dataloader()))\n",
    "\n",
    "# print(ibatch[0].shape, ibatch[1].shape, type(ibatch[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c674973-f5a6-4d61-9d77-53b1b935bf10",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdbada9e-5be2-4abd-b5bc-1693d0ef2523",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "The input data is a coordinate vector, $\\mathbf{x}_\\phi$, of the image coordinates.\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_\\phi \\in \\mathbb{R}^{D_\\phi}\n",
    "$$\n",
    "\n",
    "where $D_\\phi = [\\text{x}, \\text{y}]$. So we are interested in learning a function, $\\boldsymbol{f}$, such that we can input a coordinate vector and output a scaler/vector value of the pixel value.\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\boldsymbol{f}(\\mathbf{x}_\\phi; \\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "667bed9f-1fdc-4f68-8884-6fb0ab2dacb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "### SIREN Layer\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}^{(\\ell)}(\\mathbf{x}) = \\sin\n",
    "\\left(\n",
    "\\omega^{(\\ell)}\\left(\n",
    "\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)} + \\mathbf{s}^{(\\ell)}\n",
    "\\right)\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{s}$ is the modulation\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(\\ell)} = \\mathbf{w}_z^{(\\ell)}\\mathbf{z} + \\mathbf{b}_z^{(\\ell)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c4f22-4ae3-493a-aa90-1483c7fd2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jejeqx._src.nets.nerfs.siren import LatentModulatedSirenNet\n",
    "from jejeqx._src.nets.nerfs.siren import Siren, ModulatedSiren, LatentModulatedSiren"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5e43cb3-3a59-46ce-9694-005f15891f92",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "$$\n",
    "\\boldsymbol{\\phi}^{(\\ell)}(\\mathbf{x}) = \\sin\n",
    "\\left(\n",
    "\\omega^{(\\ell)}\\left(\n",
    "\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)}\n",
    "\\right)\\right)\n",
    "$$\n",
    "\n",
    "Notice here, there is no modulation. Just a classic SIREN layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386e5bc-f5fc-4414-8bbf-231cdac4238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "siren_layer = Siren(in_features=3, out_features=64, key=jrandom.PRNGKey(42))\n",
    "\n",
    "out = siren_layer(x_init[0])\n",
    "out.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43094c8a-d687-4d96-9441-e4c2d539915c",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "We can modify this to a *Modulated Siren* layer whereby we add a scaling modulation to the weights and biases of the later.\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}^{(\\ell)}(\\mathbf{x}) = \\sin\n",
    "\\left(\n",
    "\\omega^{(\\ell)}\\left(\n",
    "\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)} + \\mathbf{s}^{(\\ell)}\n",
    "\\right)\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{s}$ is the modulation. \n",
    "Here, we need to be very cautious about the sizes of the modulation vector, $\\mathbf{s}^{(\\ell)}$, because it can change layer-to-layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c313f-e502-4866-8f8b-07854b293c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modsiren_layer = ModulatedSiren(\n",
    "    in_features=3, out_features=64, key=jrandom.PRNGKey(123)\n",
    ")\n",
    "\n",
    "z = jrandom.normal(key=jrandom.PRNGKey(123), shape=(64,))\n",
    "out = modsiren_layer(x_init[0], z)\n",
    "out.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e14bee84-daf9-4a07-97f6-438aff90418e",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "To overcome the problem in the above *Modulated Siren* layer, we can have another NN that converts the latent vector, $\\mathbf{z}$, into the modulation parameter, $\\mathbf{s}$.\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}^{(\\ell)}(\\mathbf{x}) = \\sin\n",
    "\\left(\n",
    "\\omega^{(\\ell)}\\left(\n",
    "\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)} + \\mathbf{s}^{(\\ell)}\n",
    "\\right)\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{s}$ is the modulation\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(\\ell)}:=\\boldsymbol{s}^{(\\ell)}(\\mathbf{z}) = \\mathbf{w}_z^{(\\ell)}\\mathbf{z} + \\mathbf{b}_z^{(\\ell)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03393aab-e64d-4e76-a680-87ddc05909a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latentmodsiren_layer = LatentModulatedSiren(\n",
    "    in_features=3,\n",
    "    out_features=1,\n",
    "    latent_dim=128,\n",
    "    latent_width=64,\n",
    "    latent_depth=1,\n",
    "    latent_activation=None,\n",
    "    key=jrandom.PRNGKey(123),\n",
    ")\n",
    "\n",
    "z = jrandom.normal(key=jrandom.PRNGKey(123), shape=(128,))\n",
    "\n",
    "out = latentmodsiren_layer(x_init[0], z)\n",
    "\n",
    "out_batch = jax.vmap(latentmodsiren_layer, in_axes=(0, None))(x_init, z)\n",
    "out.shape, out_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f4600-e52d-40b3-80bf-3934765aee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = 128\n",
    "\n",
    "# @dataclass\n",
    "# class Key:\n",
    "#     _target_: str = \"jax.random.PRNGKey\"\n",
    "#     seed: int = 123\n",
    "\n",
    "# @dataclass\n",
    "# class ModSirenBasis:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.siren.ModulatedSirenNet\"\n",
    "#     in_size: int = 3\n",
    "#     out_size: int = 128\n",
    "#     width_size: int = 128\n",
    "#     depth: int = 4\n",
    "#     latent_dim: int = latent_dim\n",
    "#     key: Key = Key()\n",
    "\n",
    "# @dataclass\n",
    "# class LinearModel:\n",
    "#     _target_: str = \"equinox.nn.Linear\"\n",
    "#     in_features: int = 128\n",
    "#     out_features: int = 1\n",
    "#     use_bias: bool = True\n",
    "#     key: Key = Key()\n",
    "\n",
    "# @dataclass\n",
    "# class NerFModel:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.base.LatentNerF\"\n",
    "#     network: LinearModel = LinearModel()\n",
    "#     mod_basis_net: ModSirenBasis = ModSirenBasis()\n",
    "#     latent_dim: int = latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d58907-af54-4af5-8f45-9d60f5807cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize model\n",
    "# model_config = OmegaConf.structured(NerFModel())\n",
    "\n",
    "# model = hydra.utils.instantiate(model_config, key=jrandom.PRNGKey(123))\n",
    "\n",
    "# # check output of models\n",
    "# out = jax.vmap(model)(x_init)\n",
    "\n",
    "# assert out.shape == y_init.shape\n",
    "# # eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e772f2-4c22-48f4-a85e-aeae9f7800e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "            dims = datasets[0].coords.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5b26a-53c2-4a75-9459-738acf31946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Key:\n",
    "    _target_: str = \"jax.random.PRNGKey\"\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModSirenBasis:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.siren.LatentModulatedSirenNet\"\n",
    "    in_size: int = 3\n",
    "    out_size: int = 128\n",
    "    width_size: int = 128\n",
    "    depth: int = 4\n",
    "    latent_dim: int = latent_dim\n",
    "    latent_width: int = 128\n",
    "    latent_depth: int = 1\n",
    "    key: Key = Key()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LinearModel:\n",
    "    _target_: str = \"equinox.nn.Linear\"\n",
    "    in_features: int = 128\n",
    "    out_features: int = 1\n",
    "    use_bias: bool = True\n",
    "    key: Key = Key()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NerFModel:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.base.LatentNerF\"\n",
    "    network: LinearModel = LinearModel()\n",
    "    mod_basis_net: ModSirenBasis = ModSirenBasis()\n",
    "    latent_dim: int = latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26f7b7-3df8-4b9d-a130-ed8989ad8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_config = OmegaConf.structured(NerFModel())\n",
    "\n",
    "model = hydra.utils.instantiate(model_config, key=jrandom.PRNGKey(123))\n",
    "\n",
    "# check output of models\n",
    "out = jax.vmap(model)(x_init)\n",
    "\n",
    "assert out.shape == y_init.shape\n",
    "# eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26253b4b-f571-4839-a445-06c465c7ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_name = \"./checkpoint_model_siren_ssh.ckpt\"\n",
    "# model_loaded = eqx.tree_deserialise_leaves(f\"{save_name}\", model)\n",
    "\n",
    "# # To partially load weights: in this case load everything except the final layer.\n",
    "# model = eqx.tree_at(lambda mlp: mlp.layers[-1], model, model_original)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b3580d3-6711-4cfd-8e73-fc5703c0842b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Optimizer (+ Learning Rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bee6f311-5612-46dd-ade3-335142f3c0b3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "For this, we will use a simple adam optimizer with a `learning_rate` of 1e-4. From many studies, it appears that a lower learning rate works well with this methods because there is a lot of data. In addition, a bigger `batch_size` is also desireable. We will set the `num_epochs` to `1_000` which should be good enough for a single image. Obviously more epochs and a better learning rate scheduler would result in better results but this will be sufficient for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dc47a-bc3e-4bee-8372-4d4503dd049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Optimizer:\n",
    "    _target_: str = \"optax.adam\"\n",
    "    learning_rate: float = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca01586-a530-47d7-a552-6cc4042fa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = OmegaConf.structured(Optimizer())\n",
    "\n",
    "optim = hydra.utils.instantiate(optim_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90ebbcdb-880b-4749-9302-1aea52dcfbf6",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Scheduler\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<figcaption align = \"center\">\n",
    "  <b>Fig.1 - An example for learning rate reduction when the validation loss stagnates. Source: \n",
    "    <a href=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\">Blog</a>\n",
    "  </b>\n",
    "  </figcaption>\n",
    "</p>\n",
    "\n",
    "We will use a simple learning rate scheduler - `reduce_lr_on_plateau`. This will automatically reduce the learning rate as the validation loss stagnates. It will ensure that we really squeeze out as much performance as possible from our models during the training procedure.We start with a (relatively) high `learning_rate` of `1e-4` so we will set the `patience` to 5 epochs. So if there is no change in with every epoch, we decrease the learning rate by a factor of `0.1`.\n",
    "\n",
    "This is a rather crude (but effective) method but it tends to work well in some situations. A better method might be the `cosine_annealing` method or the `exponential_decay` method. See other [examples](https://www.kaggle.com/code/snnclsr/learning-rate-schedulers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99036348-eb3d-4d53-835d-4262c7546c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Scheduler:\n",
    "    _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "    init_value: float = 0.0\n",
    "    peak_value: float = 1e0\n",
    "    warmup_steps: int = 500\n",
    "    end_value: float = 1e-6\n",
    "\n",
    "\n",
    "scheduler_config = OmegaConf.structured(Scheduler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8676fe-0cac-465f-a1bc-f1951b1b6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3_000\n",
    "num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "scheduler = hydra.utils.instantiate(\n",
    "    scheduler_config, decay_steps=int(num_epochs * num_steps_per_epoch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461daefc-c58b-48e1-8ba3-9322095a21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.chain(optim, optax.scale_by_schedule(scheduler))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7327bdf1-7e7d-458c-99f7-2d85ba48d185",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Trainer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54b919-1dd4-4bad-bd4d-1c9d4dc92a0f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from jejeqx._src.trainers.base import TrainerModule\n",
    "from jejeqx._src.trainers.callbacks import wandb_model_artifact\n",
    "from jejeqx._src.losses import psnr\n",
    "\n",
    "\n",
    "class RegressorTrainer(TrainerModule):\n",
    "    def __init__(self, model, optimizer, **kwargs):\n",
    "        super().__init__(model=model, optimizer=optimizer, pl_logger=None, **kwargs)\n",
    "\n",
    "    def create_functions(self):\n",
    "        @eqx.filter_value_and_grad\n",
    "        def mse_loss(model, batch):\n",
    "            x, y = batch\n",
    "            pred = jax.vmap(model)(x)\n",
    "            loss = jnp.mean((y - pred) ** 2)\n",
    "            return loss\n",
    "\n",
    "        def train_step(state, batch):\n",
    "            loss, grads = mse_loss(state.params, batch)\n",
    "            state = state.update_state(state, grads)\n",
    "            psnr_loss = psnr(loss)\n",
    "            metrics = {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "            return state, loss, metrics\n",
    "\n",
    "        def eval_step(model, batch):\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        def predict_step(model, batch):\n",
    "            x, y = batch\n",
    "            out = jax.vmap(model)(x)\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return out, {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        return train_step, eval_step, predict_step\n",
    "\n",
    "    def on_training_end(\n",
    "        self,\n",
    "    ):\n",
    "        if self.pl_logger:\n",
    "            save_dir = Path(self.log_dir).joinpath(self.save_name)\n",
    "            self.save_model(save_dir)\n",
    "            wandb_model_artifact(self)\n",
    "            self.pl_logger.finalize(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df158c-9126-4e8e-b5ab-ae01c0a34c06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "train_more = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e3054-e77b-43f7-9b38-73c5566642f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.load_model(\"./checkpoints/checkpoint_model_lmsiren_ssh.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5d0fd-628d-45f4-8eff-21be28d1c977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if train_more:\n",
    "    metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe234bf6-871e-4180-818d-f4271fffc9ba",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./checkpoints/checkpoint_model_lmsiren_ssh.ckpt\")\n",
    "# trainer.save_state(\"checkpoint_state.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a93cc-dff4-4c91-a121-e17a57ce69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.predict_model(dm.predict_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1336da9-e5aa-4611-bffe-311e810c4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda[\"ssh_lmsiren\"] = dm.data_to_df(out).to_xarray().ssh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b59b43-807f-4e14-8b63-6cf8317925ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 3))\n",
    "\n",
    "vmin = np.min([xrda.ssh.min(), xrda.ssh_lmsiren.min()])\n",
    "vmax = np.min([xrda.ssh.max(), xrda.ssh_lmsiren.max()])\n",
    "\n",
    "xrda.ssh.isel(time=0).plot.pcolormesh(\n",
    "    ax=ax[0], cmap=\"viridis\", vmin=vmin, vmax=vmax, robust=True\n",
    ")\n",
    "ax[0].set(title=\"Original\")\n",
    "\n",
    "xrda.ssh_lmsiren.isel(time=0).plot.pcolormesh(\n",
    "    ax=ax[1], cmap=\"viridis\", vmin=vmin, vmax=vmax, robust=True\n",
    ")\n",
    "ax[1].set(title=\"Latent Mod Siren\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40dcdb6-4f29-4ff2-b7a1-75e033289329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pint import UnitRegistry\n",
    "from metpy.constants import earth_gravity as GRAVITY\n",
    "\n",
    "\n",
    "def get_analysis_xr(da, g: float = GRAVITY):\n",
    "    da.name = \"ssh\"\n",
    "    da.attrs[\"units\"] = \"m\"\n",
    "    da.attrs[\"long_name\"] = \"Sea Surface Height\"\n",
    "    da.attrs[\"standard_name\"] = \"sea_surface_height\"\n",
    "\n",
    "    da.time.attrs[\"long_name\"] = \"Time\"\n",
    "    da.time.attrs[\"standard_name\"] = \"time\"\n",
    "\n",
    "    da.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "    da.lon.attrs[\"long_name\"] = \"Longitude\"\n",
    "    da.lon.attrs[\"standard_name\"] = \"longitude\"\n",
    "\n",
    "    da.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "    da.lat.attrs[\"long_name\"] = \"Latitude\"\n",
    "    da.lat.attrs[\"standard_name\"] = \"latitude\"\n",
    "\n",
    "    ds = da.to_dataset()\n",
    "\n",
    "    dx, dy = metpy.calc.lat_lon_grid_deltas(longitude=ds.lon, latitude=ds.lat)\n",
    "\n",
    "    f = metpy.calc.coriolis_parameter(latitude=np.deg2rad(ds.lat.values))\n",
    "\n",
    "    f0 = f.mean()\n",
    "\n",
    "    psi = (g / f0) * da\n",
    "    ds[\"psi\"] = ((\"time\", \"lat\", \"lon\"), psi.data)\n",
    "\n",
    "    dpsi_dx, dpsi_dy = metpy.calc.geospatial_gradient(\n",
    "        f=psi, latitude=ds.lat, longitude=ds.lon\n",
    "    )\n",
    "\n",
    "    ds[\"u\"] = ((\"time\", \"lat\", \"lon\"), -dpsi_dy.magnitude)\n",
    "    ds[\"u\"].attrs[\"units\"] = dpsi_dy.u\n",
    "    ds[\"u\"].attrs[\"long_name\"] = \"Zonal Velocity\"\n",
    "    ds[\"u\"].attrs[\"standard_name\"] = \"zonal_velocity\"\n",
    "\n",
    "    ds[\"v\"] = ((\"time\", \"lat\", \"lon\"), dpsi_dx.magnitude)\n",
    "    ds[\"v\"].attrs[\"units\"] = dpsi_dx.u\n",
    "    ds[\"v\"].attrs[\"long_name\"] = \"Meridional Velocity\"\n",
    "    ds[\"v\"].attrs[\"standard_name\"] = \"meridional_velocity\"\n",
    "\n",
    "    q = metpy.calc.geospatial_laplacian(f=psi, latitude=ds.lat, longitude=ds.lon)\n",
    "    q /= f0\n",
    "    ds[\"q\"] = ((\"time\", \"lat\", \"lon\"), q.values)\n",
    "    ds[\"q\"].attrs[\"units\"] = q.data.u\n",
    "    ds[\"q\"].attrs[\"long_name\"] = \"Relative Vorticity\"\n",
    "    ds[\"q\"].attrs[\"standard_name\"] = \"relative_vorticity\"\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053cf2b-01a8-472f-a99a-5a8e32b8511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da1b2a-88c7-4601-b9c7-8b98d1a6aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_analysis(ds):\n",
    "    fig, ax = plt.subplots(ncols=4, figsize=(20, 4))\n",
    "\n",
    "    ds.ssh.isel(time=0).plot.pcolormesh(ax=ax[0], cmap=\"viridis\")\n",
    "    ds.u.isel(time=0).plot.pcolormesh(ax=ax[1], cmap=\"gray\")\n",
    "    ds.v.isel(time=0).plot.pcolormesh(ax=ax[2], cmap=\"gray\")\n",
    "    ds.q.isel(time=0).plot.pcolormesh(ax=ax[3], cmap=\"RdBu_r\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5789b665-2a1b-4e7e-8ddd-a9f83e43c886",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### NATL60 Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf1e64-8ed3-4c77-8431-26a0dd96ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ssh_analysis = get_analysis_xr(xrda.ssh)\n",
    "\n",
    "plot_analysis(\n",
    "    ds_ssh_analysis,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed9e0f20-7a64-4e55-a71c-cc43aaee077d",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Latent Modulated SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a6f87-5354-418f-bf9c-4a123a5c482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lmodsiren_analysis = get_analysis_xr(xrda.ssh_lmsiren)\n",
    "\n",
    "plot_analysis(\n",
    "    ds_lmodsiren_analysis,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df61c4-c24a-43d9-8277-dc14119d9cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-jejeqx]",
   "language": "python",
   "name": "conda-env-miniconda3-jejeqx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
