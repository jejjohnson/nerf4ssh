{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4123c4da-15c8-47f8-9781-7c14c94e2910",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "---\n",
    "title: Sparse Observations\n",
    "date: 2023-04-01\n",
    "authors:\n",
    "  - name: J. Emmanuel Johnson\n",
    "    affiliations:\n",
    "      - MEOM Lab\n",
    "    roles:\n",
    "      - Primary Programmer\n",
    "    email: jemanjohnson34@gmail.com\n",
    "license: CC-BY-4.0\n",
    "keywords: NerFs, SWOT\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028f5f4-c74e-42aa-a147-be448542e2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import autoroot\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import equinox as eqx\n",
    "import kernex as kex\n",
    "import finitediffx as fdx\n",
    "import diffrax as dfx\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import metpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from jaxtyping import Float, Array, PyTree, ArrayLike\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from sklearn import pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from jejeqx._src.transforms.dataframe.spatial import Spherical2Cartesian\n",
    "from jejeqx._src.transforms.dataframe.temporal import TimeDelta\n",
    "from jejeqx._src.transforms.dataframe.scaling import MinMaxDF\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71086b9-24cb-4b1d-9eab-93ce21ac8d12",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Recap Formulation\n",
    "\n",
    "We are interested in learning non-linear functions $\\boldsymbol{f}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{f}(\\mathbf{x}) &=\n",
    "\\mathbf{w}^\\top\\boldsymbol{\\phi}(\\mathbf{x})+\\mathbf{b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the $\\boldsymbol{\\phi}(\\cdot)$ is a basis function. Neural Fields typically try to learn this basis funciton via a series of composite functions of the form\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}(\\mathbf{x}) =\n",
    "\\boldsymbol{\\phi}_L\\circ\\boldsymbol{\\phi}_{L-1}\n",
    "\\circ\\cdots\\circ\n",
    "\\boldsymbol{\\phi}_2\\circ\\boldsymbol{\\phi}_{1}(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9495206-f1e1-42d6-beba-13fe42d9253f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Problems\n",
    "\n",
    "Here, we will demonstrate a problem that a naive network has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac67435-b31d-4788-b79d-3d2e3b5ac1df",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Sparse Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a64840-9539-4eef-b173-436d7abfe6f8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "In the previous examples, we were demonstrating how NerFs perform when we have some clean simulation. \n",
    "However, in many real problems, we do not have access to such clean\n",
    "\n",
    "For this example, we are going to look at the case when we have very sparse observations: as in the case with satellite altimetry data like SWOT. In this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c17eb7-702c-4bb4-9ae9-41736801efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /gpfswork/rech/cli/uvo53rl/projects/jejeqx/data/natl60/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a4863-5223-41b6-ae8d-19d7d1fe9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load config\n",
    "# config_dm = OmegaConf.load('./configs/natl60_obs.yaml')\n",
    "\n",
    "# # instantiate\n",
    "# # dm = hydra.utils.instantiate(config_dm.datamodule)\n",
    "# dm = hydra.utils.instantiate(config_dm.alongtrack_scaled)\n",
    "# # run setup\n",
    "# dm.setup()\n",
    "\n",
    "# # check cunits\n",
    "# (\n",
    "#     dm.ds_test[:][\"spatial\"].min(),\n",
    "#     dm.ds_test[:][\"spatial\"].max(),\n",
    "#     dm.ds_test[:][\"temporal\"].min(),\n",
    "#     dm.ds_test[:][\"temporal\"].max(),\n",
    "#     dm.ds_test[:][\"data\"].min(),\n",
    "#     dm.ds_test[:][\"data\"].max(),\n",
    "# )\n",
    "\n",
    "# len(dm.ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935674ac-e60a-4cdb-a88e-ea66587e3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "config_dm = OmegaConf.load(\"./configs/natl60_obs.yaml\")\n",
    "\n",
    "# instantiate\n",
    "# dm = hydra.utils.instantiate(config_dm.datamodule)\n",
    "dm = hydra.utils.instantiate(config_dm.alongtrack_scaled)\n",
    "# run setup\n",
    "dm.setup()\n",
    "\n",
    "# dm = hydra.utils.instantiate(config_dm.datamodule)\n",
    "dm_eval = hydra.utils.instantiate(\n",
    "    config_dm.natl60_dc20a_eval,\n",
    "    spatial_transform=dm.spatial_transform,\n",
    "    temporal_transform=dm.temporal_transform,\n",
    ")\n",
    "# run setup\n",
    "dm_eval.setup()\n",
    "\n",
    "# check cunits\n",
    "(\n",
    "    dm.ds_test[:][\"spatial\"].min(),\n",
    "    dm.ds_test[:][\"spatial\"].max(),\n",
    "    dm.ds_test[:][\"temporal\"].min(),\n",
    "    dm.ds_test[:][\"temporal\"].max(),\n",
    "    dm.ds_test[:][\"data\"].min(),\n",
    "    dm.ds_test[:][\"data\"].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc7693-7c10-4c1e-85c2-8fcb686c7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.spatial_transform.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aada7fe-c387-4dee-aea9-f60b0c698013",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm.ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e367177-80a4-4490-acdc-02d6a2932f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda = dm.load_xrds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555a3da-c0e8-4e0f-9134-d5756b9723f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5da277-9e83-4475-863c-d853d64710ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# sub_ds = xrda_obs.isel(time=slice(0,None))\n",
    "# pts = ax.scatter(sub_ds.lon, sub_ds.lat, c=sub_ds.ssh, s=0.1)\n",
    "# ax.set(\n",
    "#     xlabel=\"Longitude\",\n",
    "#     ylabel=\"Latitude\",\n",
    "# )\n",
    "\n",
    "# plt.colorbar(pts, label=\"Sea Surface Height [m]\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c0699-05b5-4473-9183-ee2fc745ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init = dm.ds_train[:32]\n",
    "x_init, t_init, y_init = init[\"spatial\"], init[\"temporal\"], init[\"data\"]\n",
    "x_init.min(), x_init.max(), x_init.shape, t_init.min(), t_init.max(), t_init.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c674973-f5a6-4d61-9d77-53b1b935bf10",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbada9e-5be2-4abd-b5bc-1693d0ef2523",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "The input data is a coordinate vector, $\\mathbf{x}_\\phi$, of the image coordinates.\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_\\phi \\in \\mathbb{R}^{D_\\phi}\n",
    "$$\n",
    "\n",
    "where $D_\\phi = [\\text{x}, \\text{y}]$. So we are interested in learning a function, $\\boldsymbol{f}$, such that we can input a coordinate vector and output a scaler/vector value of the pixel value.\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\boldsymbol{f}(\\mathbf{x}_\\phi; \\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539b1ac-a3c8-454a-81db-e9dd646d1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "model_config = OmegaConf.load(\"./configs/model.yaml\")\n",
    "\n",
    "# instantiate\n",
    "model_ffn = hydra.utils.instantiate(model_config.ffn)\n",
    "\n",
    "# test output\n",
    "out = model_ffn(x=x_init[0], t=t_init[0])\n",
    "assert out.shape == y_init[0].shape\n",
    "\n",
    "# test output (batched)\n",
    "out_batch = jax.vmap(model_ffn, in_axes=(0, 0))(x_init, t_init)\n",
    "assert out_batch.shape == y_init.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bed9f-1fdc-4f68-8884-6fb0ab2dacb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "### SIREN Layer\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}^{(\\ell)}(\\mathbf{x}) = \\sin\n",
    "\\left(\n",
    "\\omega^{(\\ell)}\\left(\n",
    "\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)} + \\mathbf{s}^{(\\ell)}\n",
    "\\right)\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{s}$ is the modulation\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(\\ell)} = \\mathbf{w}_z^{(\\ell)}\\mathbf{z} + \\mathbf{b}_z^{(\\ell)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57c78c-2361-4460-bebf-ae1d95041199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# model_config_file = \"/gpfswork/rech/cli/uvo53rl/checkpoints/nerfs/siren/nadir4/scratch/config.pkl\"\n",
    "# checkpoint_file = \"/gpfswork/rech/cli/uvo53rl/checkpoints/nerfs/siren/nadir4/scratch/checkpoint_model.ckpt\"\n",
    "\n",
    "# old_config = joblib.load(model_config_file)\n",
    "\n",
    "# model = hydra.utils.instantiate(old_config[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2304345c-3f9f-4d6d-9cd6-4f03414c7ca7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Optimizer (+ Learning Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a5fd0-7579-4bcc-bf39-ffa80d9ac05f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "For this, we will use a simple adam optimizer with a `learning_rate` of 1e-4. From many studies, it appears that a lower learning rate works well with this methods because there is a lot of data. In addition, a bigger `batch_size` is also desireable. We will set the `num_epochs` to `2_000` which should be good enough for a single image. Obviously more epochs and a better learning rate scheduler would result in better results but this will be sufficient for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b365cc-0d30-4195-b54c-1971c36ff1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "num_epochs = 250\n",
    "\n",
    "# load config\n",
    "opt_config = OmegaConf.load(\"./configs/optimizer.yaml\")\n",
    "\n",
    "# instantiate\n",
    "optimizer = hydra.utils.instantiate(opt_config.adamw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1053f0-79c4-45d6-ab97-4901ad4c133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_config = OmegaConf.load(\"./configs/lr_scheduler.yaml\")\n",
    "\n",
    "num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "scheduler = hydra.utils.instantiate(\n",
    "    scheduler_config.warmup_cosine, decay_steps=int(num_epochs * num_steps_per_epoch)\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(optimizer, optax.scale_by_schedule(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26c546-b107-4474-918e-e2a4e55b7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65305e8e-1d69-4399-9c5f-8c99a150eece",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Trainer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640ca8b-22ee-4557-8070-110913f9e90d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from jejeqx._src.trainers.base import TrainerModule\n",
    "from jejeqx._src.trainers.callbacks import wandb_model_artifact\n",
    "from jejeqx._src.losses import psnr\n",
    "\n",
    "\n",
    "class RegressorTrainer(TrainerModule):\n",
    "    def __init__(self, model, optimizer, **kwargs):\n",
    "        super().__init__(model=model, optimizer=optimizer, pl_logger=None, **kwargs)\n",
    "\n",
    "    def create_functions(self):\n",
    "        @eqx.filter_value_and_grad\n",
    "        def mse_loss(model, batch):\n",
    "            x, t, y = batch[\"spatial\"], batch[\"temporal\"], batch[\"data\"]\n",
    "            pred = jax.vmap(model, in_axes=(0, 0))(x, t)\n",
    "            loss = jnp.mean((y - pred) ** 2)\n",
    "            return loss\n",
    "\n",
    "        def train_step(state, batch):\n",
    "            loss, grads = mse_loss(state.params, batch)\n",
    "            state = state.update_state(state, grads)\n",
    "            psnr_loss = psnr(loss)\n",
    "            metrics = {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "            return state, loss, metrics\n",
    "\n",
    "        def eval_step(model, batch):\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        def test_step(model, batch):\n",
    "            x, t = batch[\"spatial\"], batch[\"temporal\"]\n",
    "            out = jax.vmap(model, in_axes=(0, 0))(x, t)\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return out, {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        def predict_step(model, batch):\n",
    "            x, t = batch[\"spatial\"], batch[\"temporal\"]\n",
    "            out = jax.vmap(model, in_axes=(0, 0))(x, t)\n",
    "            return out\n",
    "\n",
    "        return train_step, eval_step, test_step, predict_step\n",
    "\n",
    "    def on_training_end(\n",
    "        self,\n",
    "    ):\n",
    "        if self.pl_logger:\n",
    "            save_dir = Path(self.log_dir).joinpath(self.save_name)\n",
    "            self.save_model(save_dir)\n",
    "            wandb_model_artifact(self)\n",
    "            self.pl_logger.finalize(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21745e2c-1e75-40e7-9720-766872d90763",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model_ffn,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "train_more = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f616738-1fb9-4b4d-a7cb-6c8e5c96b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2bd25-3110-4579-9517-e965beead1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.load_model(\"./checkpoints/checkpoint_model_rff_osse_nadir.ckpt\")\n",
    "    # trainer.load_model(\"./checkpoints/checkpoint_model_rff_ssh.ckpt\")\n",
    "    pass\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671aa7f1-3b70-415d-8d65-783a1f6f8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccbfc9-f0ec-462d-b03e-62255d8064b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if train_more:\n",
    "    metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08712e1b-e9f5-42b9-9fdd-b08daf269ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f911d-5b77-4d8b-9dc3-94a80b22db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd4aa9-16f7-42a3-9c02-87783302ddfe",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if train_more:\n",
    "    trainer.save_model(\"./checkpoints/checkpoint_model_rff_osse_nadir.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20119d69-c024-435f-9c92-720bc2cc8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame()\n",
    "all_metrics = pd.concat(\n",
    "    [\n",
    "        all_metrics,\n",
    "        pd.DataFrame(\n",
    "            data=[[\"rff\", metrics[\"loss\"], metrics[\"psnr\"]]],\n",
    "            columns=[\"model\", \"MSE\", \"PSNR\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980d448-b03c-4d13-b6fb-f29c1114a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda = dm_eval.load_xrds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6aac7-11c7-4ce8-83b2-2898a33e23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.test_model(dm_eval.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed818d0e-ec74-4fc6-9683-a0a174c20088",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda[\"ssh_rff\"] = ((\"time\", \"lat\", \"lon\"), dm_eval.data_to_df(out).to_xarray().ssh.data)\n",
    "xrda[\"ssh_rff\"].attrs[\"standard_name\"] = \"Sea Surface Height\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a836ce-ef42-4e2c-a111-44d0d5cabd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_fn_rff = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5638f5-f75b-46ea-aeff-02e1c0ddd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(12, 3))\n",
    "\n",
    "itime = \"2012-10-22\"\n",
    "\n",
    "xrda.ssh.sel(time=itime).plot.pcolormesh(ax=ax[0], cmap=\"viridis\")\n",
    "ax[0].set(title=\"Original\")\n",
    "\n",
    "# xrda.ssh_mlp.isel(time=0).plot.pcolormesh(ax=ax[1], cmap=\"viridis\")\n",
    "# ax[1].set(title=\"Naive MLP\")\n",
    "\n",
    "xrda.ssh_rff.sel(time=itime).plot.pcolormesh(ax=ax[2], cmap=\"viridis\")\n",
    "ax[2].set(title=\"Fourier Features\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c874f6c-49ba-431a-8bea-75ae0ccfa045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "from jejeqx._src.transforms.xarray.geostrophic import calculate_coriolis\n",
    "from metpy.constants import earth_gravity\n",
    "\n",
    "f0: Array = jnp.asarray(1e-5)\n",
    "g: Array = jnp.asarray(earth_gravity.magnitude)\n",
    "c: Array = jnp.asarray(1.5)\n",
    "# f0: Array = jnp.asarray(calculate_coriolis(xrda.lat).data.magnitude)\n",
    "# g: Array = jnp.asarray(earth_gravity.magnitude)\n",
    "\n",
    "\n",
    "def create_streamfn(f: tp.Callable, f0: float = 1e-5, g: float = 9.81) -> tp.Callable:\n",
    "    def sfn(x: Array, t: Array) -> Array:\n",
    "        return (g / f0) * f(x, t)\n",
    "\n",
    "    return sfn\n",
    "\n",
    "\n",
    "def create_gradient_fn(f: tp.Callable) -> tp.Callable:\n",
    "    def fn(x: Array, t: Array) -> Array:\n",
    "        return jax.jacfwd(f)(x, t).squeeze()\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "def uv_velocity(grad_psi: Array) -> tp.Tuple[Array, Array]:\n",
    "    dpsi_x, dpsi_y = jnp.split(grad_psi, 2, axis=-1)\n",
    "\n",
    "    u = -dpsi_y\n",
    "    v = dpsi_x\n",
    "    return u, v\n",
    "\n",
    "\n",
    "def create_laplacian_fn(f: tp.Callable) -> tp.Callable:\n",
    "    def fn(x: Array, t: Array) -> Array:\n",
    "        # return jax.jacfwd(jax.jacrev(f))(x)\n",
    "        H = jax.hessian(f)\n",
    "        L = jnp.diagonal(H(x, t)[0])\n",
    "        return jnp.sum(L, keepdims=True)\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "def create_pvort_fn(f: tp.Callable, f0: float = 1e-5, c: float = 1.5) -> tp.Callable:\n",
    "    rvort_fn = create_laplacian_fn(f)\n",
    "\n",
    "    def fn(x: Array, t: Array) -> Array:\n",
    "        rvort = rvort_fn(x, t)\n",
    "        return rvort - (f0 / c) ** 2 * f(x, t)\n",
    "\n",
    "    return fn\n",
    "\n",
    "\n",
    "def create_advection_fn(f: tp.Callable) -> tp.Callable:\n",
    "    pvort_fn = create_pvort_fn(f)\n",
    "    grad_pvort_fn = create_gradient_fn(pvort_fn)\n",
    "    grad_psi_fn = create_gradient_fn(f)\n",
    "\n",
    "    def fn(x: Array, t: Array) -> Array:\n",
    "        # gradient of potential vorticity\n",
    "        grad_pvort = grad_pvort_fn(x, t)\n",
    "        pvort_x, pvort_y = jnp.split(grad_pvort, 2, axis=-1)\n",
    "        # u, v - velocity\n",
    "        grad_psi = grad_psi_fn(x, t)\n",
    "        u, v = uv_velocity(grad_psi)\n",
    "        return u * pvort_x + v * pvort_y\n",
    "\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc779b76-eb39-46fc-8aa5-f426d0e0d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh_fn = trainer.model\n",
    "psi_fn = create_streamfn(ssh_fn)\n",
    "grad_psi_fn = create_gradient_fn(psi_fn)\n",
    "rvort_fn = create_laplacian_fn(psi_fn)\n",
    "pvort_fn = create_pvort_fn(psi_fn)\n",
    "rhs_fn = create_advection_fn(psi_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08492301-b824-426c-b5d4-7bbddf2b1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = ssh_fn(x_init[10], y_init[10])\n",
    "psi = psi_fn(x_init[10], y_init[10])\n",
    "rvort = rvort_fn(x_init[10], y_init[10])\n",
    "pvort = pvort_fn(x_init[10], y_init[10])\n",
    "rhs = rhs_fn(x_init[10], y_init[10])\n",
    "eta.shape, psi.shape, rvort.shape, pvort.shape, rhs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f5a17-9719-42f7-82e2-3d49fb74badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta, psi, rvort, pvort, rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f02949-0b7c-470a-8a92-3d355abfb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qg_loss_fn(f, f0, g, c):\n",
    "    \n",
    "    psi_fn = create_streamfn(ff=f, f0=f0, g=g)\n",
    "    \n",
    "    grad_psi_fn = create_gradient_fn(psi_fn)\n",
    "    \n",
    "    rvort_fn = create_laplacian_fn(psi_fn)\n",
    "    \n",
    "    grad_psi_fn = create_gradient_fn(psi_fn)\n",
    "    \n",
    "    def residual_fn(x, t):\n",
    "        # calculate psi\n",
    "        psi = psi_fn(x, t)\n",
    "        # calculate relative vorticity\n",
    "        rvort = rvort_fn(x, t)\n",
    "        # calculate the gradient of psi\n",
    "        grad_psi = grad_fn(x, t)\n",
    "        \n",
    "        # calculate u, v\n",
    "        u, v = uv_velocity(grad_psi)\n",
    "        dq_dx, dq_dy = grad_fn(\n",
    "        # calculate advection\n",
    "        rhs = u * \n",
    "        return None\n",
    "    return residual_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ff497-e769-4151-9128-37f9301bf94c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{R}(\\boldsymbol{\\theta}) =\n",
    "\\partial_t q - u \\partial_x q + v\\partial_y q\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\psi& = \\frac{g}{f_0}\\eta \\\\\n",
    "q &= \\nabla^2\\psi - \\frac{f_0^2}{c_1^2}\\psi\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d51ff8-ad49-4d64-bafe-b54a044adcd3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We will predict the whole dataset at the full resolution available for the same time period.\n",
    "\n",
    "`01-June-2013 :--> 15-June-2013`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894b25c-5ade-4270-9294-4927cf90b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SSHDMEVAL:\n",
    "    _target_: str = \"jejeqx._src.datamodules.coords.EvalCoordDM\"\n",
    "    paths: str = \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/test/dc_ref/NATL60-CJM165_GULFSTREAM*\"\n",
    "    batch_size: int = 10_000\n",
    "    shuffle: bool = False\n",
    "    train_size: float = 0.80\n",
    "    decode_times: bool = True\n",
    "    evaluation: bool = True\n",
    "    spatial_coords: List = field(default_factory=lambda: [\"lat\", \"lon\"])\n",
    "    temporal_coords: List = field(default_factory=lambda: [\"time\"])\n",
    "    variables: List = field(default_factory=lambda: [\"sossheig\"])\n",
    "    coarsen: Dict = field(default_factory=lambda: {\"lon\": 2, \"lat\": 2})\n",
    "    resample: str = \"1D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f1ee9-07d7-4d76-82b8-69453a87e036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# select = {\"time\": slice(\"2012-10-22\", \"2012-11-22\")}\n",
    "select = {\"time\": slice(\"2012-10-22\", \"2012-12-02\")}\n",
    "\n",
    "config_dm = OmegaConf.structured(SSHDMEVAL())\n",
    "\n",
    "dm_eval = hydra.utils.instantiate(\n",
    "    config_dm,\n",
    "    select=select,\n",
    "    spatial_transform=dm.spatial_transform,\n",
    "    temporal_transform=dm.temporal_transform,\n",
    ")\n",
    "\n",
    "dm_eval.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca3be9-35e9-40e8-beac-736a1cf4fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num Points: {len(dm_eval.ds_test):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d527f-181e-4ca1-8da1-a586246dd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xrda = dm_eval.load_xrds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a93cc-dff4-4c91-a121-e17a57ce69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.test_model(dm_eval.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1336da9-e5aa-4611-bffe-311e810c4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda[\"ssh_rff\"] = dm_eval.data_to_df(out).to_xarray().sossheig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd50f4b-d831-4197-aa6a-e596b3f2988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_utils as cutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c1275-1ccb-4221-90c6-a59be09b4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rff = cutils.calculate_physical_quantities(xrda.ssh_rff)\n",
    "ds_natl60 = cutils.calculate_physical_quantities(xrda.sossheig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1039f4-249d-41f7-b6bd-487650c43ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cutils.plot_analysis_vars(\n",
    "    [\n",
    "        ds_natl60.isel(time=-1),\n",
    "        ds_rff.isel(time=-1),\n",
    "    ]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949195b9-6d5e-44da-addb-c1a596f0dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_natl60 = cutils.calculate_isotropic_psd(ds_natl60)\n",
    "ds_psd_rff = cutils.calculate_isotropic_psd(ds_rff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70dfd3a-e61c-4a24-836d-fb46c6021e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cutils.plot_analysis_psd_iso(\n",
    "    [\n",
    "        ds_psd_natl60,\n",
    "        ds_psd_rff,\n",
    "    ],\n",
    "    [\n",
    "        \"NATL60\",\n",
    "        \"RFE\",\n",
    "    ],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7e56a-7751-476e-9998-c44634d5fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_scores = cutils.calculate_isotropic_psd_score(ds_rff, ds_natl60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ec588-7873-48fb-8d48-17739a29127e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutils.plot_analysis_psd_iso_score([ds_psd_scores], [\"SIREN\"], [\"k\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e0237-b4e1-4709-a03f-6bd3a026ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ivar in ds_psd_scores:\n",
    "    resolved_spatial_scale = ds_psd_scores[ivar].attrs[\"resolved_scale_space\"] / 1e3\n",
    "    print(f\"Wavelength [km]: {resolved_spatial_scale:.2f} [{ivar.upper()}]\")\n",
    "    print(f\"Wavelength [degree]: {resolved_spatial_scale/111:.2f} [{ivar.upper()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78dac32-4cee-4b8d-a3dc-dd0e0c007724",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_natl60 = cutils.calculate_spacetime_psd(ds_natl60)\n",
    "ds_psd_rff = cutils.calculate_spacetime_psd(ds_rff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a74eb6-28a1-4ba5-96ac-78250239905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cutils.plot_analysis_psd_spacetime(\n",
    "    [\n",
    "        ds_psd_natl60,\n",
    "        ds_psd_rff,\n",
    "    ],\n",
    "    [\n",
    "        \"NATL60\",\n",
    "        \"RFE\",\n",
    "    ],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb9e5f-ef8b-40de-b528-5cd31ccb675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_rff = cutils.calculate_spacetime_psd_score(ds_rff, ds_natl60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c842db5-6ac8-4be4-ab26-22e96997ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ivar in ds_psd_rff:\n",
    "    resolved_spatial_scale = ds_psd_rff[ivar].attrs[\"resolved_scale_space\"] / 1e3\n",
    "    print(f\"Resolved Scale [km]: {resolved_spatial_scale:.2f} [{ivar.upper()}]\")\n",
    "    resolved_temporal_scale = ds_psd_rff[ivar].attrs[\"resolved_scale_time\"]\n",
    "    print(f\"Resolved Scale [days]: {resolved_temporal_scale:.2f}  [{ivar.upper()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b43d1-afb3-4187-97d0-95d2a4d1e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cutils.plot_analysis_psd_spacetime_score([ds_psd_rff], [\"rff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9f422-ed42-4368-8917-18ea47c27e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-jejeqx]",
   "language": "python",
   "name": "conda-env-miniconda3-jejeqx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
