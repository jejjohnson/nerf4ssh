{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4123c4da-15c8-47f8-9781-7c14c94e2910",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "<!-- ---\n",
    "title: Sparse Observations\n",
    "date: 2023-04-01\n",
    "authors:\n",
    "  - name: J. Emmanuel Johnson\n",
    "    affiliations:\n",
    "      - MEOM Lab\n",
    "    roles:\n",
    "      - Primary Programmer\n",
    "    email: jemanjohnson34@gmail.com\n",
    "license: CC-BY-4.0\n",
    "keywords: NerFs, SWOT\n",
    "--- -->\n",
    "# OSSE SWOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028f5f4-c74e-42aa-a147-be448542e2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import autoroot\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import equinox as eqx\n",
    "import kernex as kex\n",
    "import finitediffx as fdx\n",
    "import diffrax as dfx\n",
    "import xarray as xr\n",
    "import metpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from jaxtyping import Float, Array, PyTree, ArrayLike\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from sklearn import pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from jejeqx._src.transforms.dataframe.spatial import Spherical2Cartesian\n",
    "from jejeqx._src.transforms.dataframe.temporal import TimeDelta\n",
    "from jejeqx._src.transforms.dataframe.scaling import MinMaxDF\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c71086b9-24cb-4b1d-9eab-93ce21ac8d12",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Recap Formulation\n",
    "\n",
    "We are interested in learning non-linear functions $\\boldsymbol{f}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{f}(\\mathbf{x}) &=\n",
    "\\mathbf{w}^\\top\\boldsymbol{\\phi}(\\mathbf{x})+\\mathbf{b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the $\\boldsymbol{\\phi}(\\cdot)$ is a basis function. Neural Fields typically try to learn this basis funciton via a series of composite functions of the form\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}(\\mathbf{x}) =\n",
    "\\boldsymbol{\\phi}_L\\circ\\boldsymbol{\\phi}_{L-1}\n",
    "\\circ\\cdots\\circ\n",
    "\\boldsymbol{\\phi}_2\\circ\\boldsymbol{\\phi}_{1}(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9495206-f1e1-42d6-beba-13fe42d9253f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Problems\n",
    "\n",
    "Here, we will demonstrate a problem that a naive network has."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ac67435-b31d-4788-b79d-3d2e3b5ac1df",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Sparse Observations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1a64840-9539-4eef-b173-436d7abfe6f8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "In the previous examples, we were demonstrating how NerFs perform when we have some clean simulation. \n",
    "However, in many real problems, we do not have access to such clean\n",
    "\n",
    "For this example, we are going to look at the case when we have very sparse observations: as in the case with satellite altimetry data like SWOT. In this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d5566-74c1-484e-9469-e5b95ddd9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "files = [\n",
    "    \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/work_eman/ml_ready/swot1nadir5.nc\",\n",
    "    # \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/work_eman/ml_ready/nadir4.nc\",\n",
    "]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SSHDM:\n",
    "    _target_: str = \"jejeqx._src.datamodules.coords.AlongTrackDM\"\n",
    "    paths: List[str] = field(default_factory=lambda: files)\n",
    "    batch_size: int = 10_000\n",
    "    shuffle: bool = True\n",
    "    train_size: float = 0.80\n",
    "    decode_times: bool = True\n",
    "    spatial_coords: List = field(default_factory=lambda: [\"lat\", \"lon\"])\n",
    "    temporal_coords: List = field(default_factory=lambda: [\"time\"])\n",
    "    variables: List = field(default_factory=lambda: [\"ssh_obs\"])\n",
    "\n",
    "\n",
    "# spatial transform\n",
    "spatial_transforms = Pipeline(\n",
    "    [\n",
    "        (\"cartesian3d\", Spherical2Cartesian(radius=1.0, units=\"degrees\")),\n",
    "        (\"spatialminmax\", MinMaxDF([\"x\", \"y\", \"z\"], -1, 1)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "temporal_transforms = Pipeline(\n",
    "    [\n",
    "        (\"timedelta\", TimeDelta(\"2012-10-01\", 1, \"s\")),\n",
    "        (\"timeminmax\", MinMaxDF([\"time\"], -1, 1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bf5af-e023-4d3b-a5bc-4bd14de193a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = {\"time\": slice(\"2012-10-01\", \"2012-12-02\")}\n",
    "\n",
    "config_dm = OmegaConf.structured(SSHDM())\n",
    "\n",
    "dm = hydra.utils.instantiate(\n",
    "    config_dm,\n",
    "    select=select,\n",
    "    spatial_transform=spatial_transforms,\n",
    "    temporal_transform=temporal_transforms,\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "\n",
    "init = dm.ds_train[:32]\n",
    "x_init, t_init, y_init = init[\"spatial\"], init[\"temporal\"], init[\"data\"]\n",
    "x_init.min(), x_init.max(), x_init.shape, t_init.min(), t_init.max(), t_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aada7fe-c387-4dee-aea9-f60b0c698013",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm.ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e367177-80a4-4490-acdc-02d6a2932f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda_obs = dm.load_xrds()\n",
    "xrda_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5da277-9e83-4475-863c-d853d64710ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(ncols=1, figsize=(5,4))\n",
    "\n",
    "# xrda_obs.ssh_obs.isel(time=1).plot.pcolormesh(ax=ax, cmap=\"viridis\")\n",
    "# ax.set(title=\"Original\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6041259-00a2-4de1-85b1-2569744ee922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geoviews as gv\n",
    "# import geoviews.feature as gf\n",
    "# from cartopy import crs\n",
    "\n",
    "# gv.extension('bokeh', 'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2043e33-8790-4e66-af64-c7f0f2758af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xrda_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d8c5d-7fe3-4d1f-8943-d8268fc87de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = gv.Dataset(xrda_obs)\n",
    "# ensemble1 = dataset.to(gv.Image, ['lon', 'lat'], \"ssh_obs\")\n",
    "# gv.output(ensemble1.opts(cmap='viridis', colorbar=True, fig_size=200, backend='matplotlib') * gf.coastline(),\n",
    "#           backend='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ffb2f-decd-4b19-ad3a-ee264c1088df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 5e-3\n",
    "# num_epochs = 5_000\n",
    "# num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "# @dataclass\n",
    "# class FoxDataModule:\n",
    "#     _target_: str = \"jejeqx._src.datamodules.image.ImageFox\"\n",
    "#     batch_size: int = 10_000\n",
    "#     train_size: float = 0.5\n",
    "#     shuffle: bool = False\n",
    "#     split_method: str = \"even\"\n",
    "#     resize: int = 4\n",
    "\n",
    "# @dataclass\n",
    "# class Training:\n",
    "#     num_epochs: int = 2_000\n",
    "\n",
    "# @dataclass\n",
    "# class Model:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.siren.SirenNet\"\n",
    "#     in_size: int = 2\n",
    "#     out_size: int = 3\n",
    "#     width_size: int = 128\n",
    "#     depth: int = 5\n",
    "\n",
    "# @dataclass\n",
    "# class Optimizer:\n",
    "#     _target_: str = \"optax.adam\"\n",
    "#     learning_rate: float = lr\n",
    "\n",
    "# @dataclass\n",
    "# class Scheduler:\n",
    "#     _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "#     init_value: float = 0.0\n",
    "#     peak_value: float = lr\n",
    "#     warmup_steps: int = 100\n",
    "#     decay_steps: int = int(num_epochs * num_steps_per_epoch)\n",
    "#     end_value: float = 0.01 * lr\n",
    "\n",
    "# @dataclass\n",
    "# class Config:\n",
    "#     datamodule: FoxDataModule = FoxDataModule()\n",
    "#     model: Model = Model()\n",
    "#     optimizer: Optimizer = Optimizer()\n",
    "#     scheduler: Scheduler = Scheduler()\n",
    "#     num_epochs: int = 2_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc918a-caec-4696-9e70-1d101b62d0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import optax\n",
    "\n",
    "# config = Config()\n",
    "# config = OmegaConf.structured(Config())\n",
    "\n",
    "# # initialize datamodule\n",
    "# dm = hydra.utils.instantiate(config.datamodule)\n",
    "\n",
    "# dm.setup()\n",
    "\n",
    "\n",
    "# # initialize optimizer\n",
    "# optimizer = hydra.utils.instantiate(config.optimizer)\n",
    "\n",
    "# # initialize scheduler\n",
    "# num_steps_per_epoch = len(dm.ds_train)\n",
    "# decay_steps = int(num_steps_per_epoch * config.num_epochs)\n",
    "# schedule_fn = hydra.utils.instantiate(config.scheduler, decay_steps=decay_steps)\n",
    "\n",
    "# # initialize optimizer + scheduler\n",
    "# optimizer = optax.chain(optimizer, optax.scale_by_schedule(schedule_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7ad02-d923-4fca-b106-ce87652b9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibatch = next(iter(dm.train_dataloader()))\n",
    "\n",
    "# print(ibatch[0].shape, ibatch[1].shape, type(ibatch[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c674973-f5a6-4d61-9d77-53b1b935bf10",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdbada9e-5be2-4abd-b5bc-1693d0ef2523",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "The input data is a coordinate vector, $\\mathbf{x}_\\phi$, of the image coordinates.\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_\\phi \\in \\mathbb{R}^{D_\\phi}\n",
    "$$\n",
    "\n",
    "where $D_\\phi = [\\text{x}, \\text{y}]$. So we are interested in learning a function, $\\boldsymbol{f}$, such that we can input a coordinate vector and output a scaler/vector value of the pixel value.\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\boldsymbol{f}(\\mathbf{x}_\\phi; \\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "667bed9f-1fdc-4f68-8884-6fb0ab2dacb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "### SIREN Layer\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}^{(\\ell)}(\\mathbf{x}) = \\sin\n",
    "\\left(\n",
    "\\omega^{(\\ell)}\\left(\n",
    "\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)} + \\mathbf{s}^{(\\ell)}\n",
    "\\right)\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{s}$ is the modulation\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(\\ell)} = \\mathbf{w}_z^{(\\ell)}\\mathbf{z} + \\mathbf{b}_z^{(\\ell)}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb6b3360-0d83-494b-a9a3-750c0f41abbe",
   "metadata": {},
   "source": [
    "### Siren Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b7c0e-e652-48b6-a0fb-11f0f3a70050",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /gpfswork/rech/cli/uvo53rl/checkpoints/nerfs/siren/swot1nadir5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57c78c-2361-4460-bebf-ae1d95041199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_saved = \"pretrained\"  # \"scratch\" #\n",
    "model_config_file = f\"/gpfswork/rech/cli/uvo53rl/checkpoints/nerfs/siren/swot1nadir5/{model_saved}/config.pkl\"\n",
    "checkpoint_file = f\"/gpfswork/rech/cli/uvo53rl/checkpoints/nerfs/siren/swot1nadir5/{model_saved}/checkpoint_model.ckpt\"\n",
    "\n",
    "old_config = joblib.load(model_config_file)\n",
    "\n",
    "model = hydra.utils.instantiate(old_config[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75094d0f-21d6-4422-b4ea-3ab4c66e60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jejeqx._src.nets.nerfs.ffn import RFFLayer\n",
    "\n",
    "model_name = \"rff\"\n",
    "\n",
    "\n",
    "model = eqx.nn.Sequential(\n",
    "    [\n",
    "        RFFLayer(in_dim=4, num_features=256, out_dim=256, key=jrandom.PRNGKey(42)),\n",
    "        RFFLayer(in_dim=256, num_features=256, out_dim=256, key=jrandom.PRNGKey(123)),\n",
    "        RFFLayer(in_dim=256, num_features=256, out_dim=256, key=jrandom.PRNGKey(23)),\n",
    "        RFFLayer(in_dim=256, num_features=256, out_dim=256, key=jrandom.PRNGKey(81)),\n",
    "        RFFLayer(in_dim=256, num_features=256, out_dim=1, key=jrandom.PRNGKey(32)),\n",
    "    ]\n",
    ")\n",
    "# check output of models\n",
    "out = jax.vmap(model)(jnp.hstack([x_init, t_init]))\n",
    "\n",
    "assert out.shape == y_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43813782-11a0-444d-9a41-bcffbdf4523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"siren\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Key:\n",
    "    _target_: str = \"jax.random.PRNGKey\"\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SirenBasis:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.siren.SirenNet\"\n",
    "    in_size: int = 4\n",
    "    out_size: int = 256\n",
    "    width_size: int = 256\n",
    "    depth: int = 5\n",
    "    key: Key = Key()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LinearModel:\n",
    "    _target_: str = \"equinox.nn.Linear\"\n",
    "    in_features: int = 256\n",
    "    out_features: int = 1\n",
    "    use_bias: bool = True\n",
    "    key: Key = Key()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NerFModel:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.base.NerF\"\n",
    "    # basis_net: RFFBasis = RFFBasis()\n",
    "    basis_net: SirenBasis = SirenBasis()\n",
    "    network: LinearModel = LinearModel()\n",
    "\n",
    "\n",
    "# initialize model\n",
    "model_config = OmegaConf.structured(NerFModel())\n",
    "\n",
    "model = hydra.utils.instantiate(model_config)\n",
    "\n",
    "# check output of models\n",
    "out = jax.vmap(model)(jnp.hstack([x_init, t_init]))\n",
    "\n",
    "assert out.shape == y_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43cce5-0ff2-41ba-ad78-99a1a35d3a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b3580d3-6711-4cfd-8e73-fc5703c0842b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Optimizer (+ Learning Rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bee6f311-5612-46dd-ade3-335142f3c0b3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "For this, we will use a simple adam optimizer with a `learning_rate` of 1e-4. From many studies, it appears that a lower learning rate works well with this methods because there is a lot of data. In addition, a bigger `batch_size` is also desireable. We will set the `num_epochs` to `1_000` which should be good enough for a single image. Obviously more epochs and a better learning rate scheduler would result in better results but this will be sufficient for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dc47a-bc3e-4bee-8372-4d4503dd049a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca01586-a530-47d7-a552-6cc4042fa9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90ebbcdb-880b-4749-9302-1aea52dcfbf6",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Scheduler\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<figcaption align = \"center\">\n",
    "  <b>Fig.1 - An example for learning rate reduction when the validation loss stagnates. Source: \n",
    "    <a href=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\">Blog</a>\n",
    "  </b>\n",
    "  </figcaption>\n",
    "</p>\n",
    "\n",
    "We will use a simple learning rate scheduler - `reduce_lr_on_plateau`. This will automatically reduce the learning rate as the validation loss stagnates. It will ensure that we really squeeze out as much performance as possible from our models during the training procedure.We start with a (relatively) high `learning_rate` of `1e-4` so we will set the `patience` to 5 epochs. So if there is no change in with every epoch, we decrease the learning rate by a factor of `0.1`.\n",
    "\n",
    "This is a rather crude (but effective) method but it tends to work well in some situations. A better method might be the `cosine_annealing` method or the `exponential_decay` method. See other [examples](https://www.kaggle.com/code/snnclsr/learning-rate-schedulers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99036348-eb3d-4d53-835d-4262c7546c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "num_epochs = 1_000\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Optimizer:\n",
    "    _target_: str = \"optax.adam\"\n",
    "    learning_rate: float = 1e-4\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class Scheduler:\n",
    "#     _target_: str = \"optax.warmup_exponential_decay_schedule\"\n",
    "#     init_value: float = 0.0\n",
    "#     peak_value: float = 1e-2\n",
    "#     warmup_steps: int = 100\n",
    "#     end_value: float = 1e-5\n",
    "#     decay_rate: float = 0.1\n",
    "\n",
    "\n",
    "# FINETUNE!\n",
    "@dataclass\n",
    "class Scheduler:\n",
    "    _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "    init_value: float = 0.0\n",
    "    peak_value: float = 1e-2\n",
    "    warmup_steps: int = 500\n",
    "    end_value: float = 1e-6\n",
    "\n",
    "\n",
    "scheduler_config = OmegaConf.structured(Scheduler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8676fe-0cac-465f-a1bc-f1951b1b6e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim_config = OmegaConf.structured(Optimizer())\n",
    "\n",
    "optimizer = hydra.utils.instantiate(optim_config)\n",
    "\n",
    "# num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "# scheduler = hydra.utils.instantiate(\n",
    "#     scheduler_config,\n",
    "#     decay_steps=int(num_epochs * num_steps_per_epoch)\n",
    "# )\n",
    "\n",
    "# optimizer = optax.chain(optimizer, optax.scale_by_schedule(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461daefc-c58b-48e1-8ba3-9322095a21b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7327bdf1-7e7d-458c-99f7-2d85ba48d185",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Trainer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54b919-1dd4-4bad-bd4d-1c9d4dc92a0f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from jejeqx._src.trainers.base import TrainerModule\n",
    "from jejeqx._src.trainers.callbacks import wandb_model_artifact\n",
    "from jejeqx._src.losses import psnr\n",
    "\n",
    "\n",
    "class RegressorTrainer(TrainerModule):\n",
    "    def __init__(self, model, optimizer, **kwargs):\n",
    "        super().__init__(model=model, optimizer=optimizer, pl_logger=None, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.state.params\n",
    "\n",
    "    @property\n",
    "    def model_batch(self):\n",
    "        return jax.vmap(self.state.params, in_axes=(0, 0))\n",
    "\n",
    "    def create_functions(self):\n",
    "        @eqx.filter_value_and_grad\n",
    "        def mse_loss(model, batch):\n",
    "            x, t, y = batch[\"spatial\"], batch[\"temporal\"], batch[\"data\"]\n",
    "            # pred = jax.vmap(model, in_axes=(0,0))(x, t)\n",
    "            pred = jax.vmap(model)(jnp.hstack([x, t]))\n",
    "            loss = jnp.mean((y - pred) ** 2)\n",
    "            return loss\n",
    "\n",
    "        def train_step(state, batch):\n",
    "            loss, grads = mse_loss(state.params, batch)\n",
    "            state = state.update_state(state, grads)\n",
    "            psnr_loss = psnr(loss)\n",
    "            metrics = {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "            return state, loss, metrics\n",
    "\n",
    "        def eval_step(model, batch):\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        def test_step(model, batch):\n",
    "            x, t, y = batch[\"spatial\"], batch[\"temporal\"], batch[\"data\"]\n",
    "            pred = jax.vmap(model)(jnp.hstack([x, t]))\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return pred, {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        def predict_step(model, batch):\n",
    "            x, t = batch[\"spatial\"], batch[\"temporal\"]\n",
    "            pred = jax.vmap(model)(jnp.hstack([x, t]))\n",
    "            return pred\n",
    "\n",
    "        return train_step, eval_step, test_step, predict_step\n",
    "\n",
    "    def on_training_end(\n",
    "        self,\n",
    "    ):\n",
    "        if self.pl_logger:\n",
    "            save_dir = Path(self.log_dir).joinpath(self.save_name)\n",
    "            self.save_model(save_dir)\n",
    "            wandb_model_artifact(self)\n",
    "            self.pl_logger.finalize(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df158c-9126-4e8e-b5ab-ae01c0a34c06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "train_more = True\n",
    "save_more = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54591d79-21a2-4787-8bb8-7f25c595f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00df747-9f52-483e-84dc-a554cfc72ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model(checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616b022-0b0b-42bd-ad8a-eb8683311ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5d0fd-628d-45f4-8eff-21be28d1c977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad3663-3e31-4504-a584-fadb4a5b0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96d51ff8-ad49-4d64-bafe-b54a044adcd3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We will predict the whole dataset at the full resolution available for the same time period.\n",
    "\n",
    "`01-June-2013 :--> 15-June-2013`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894b25c-5ade-4270-9294-4927cf90b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SSHDMEVAL:\n",
    "    _target_: str = \"jejeqx._src.datamodules.coords.EvalCoordDM\"\n",
    "    paths: str = \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/test/dc_ref/NATL60-CJM165_GULFSTREAM*\"\n",
    "    batch_size: int = 10_000\n",
    "    shuffle: bool = False\n",
    "    train_size: float = 0.80\n",
    "    decode_times: bool = True\n",
    "    evaluation: bool = True\n",
    "    spatial_coords: List = field(default_factory=lambda: [\"lat\", \"lon\"])\n",
    "    temporal_coords: List = field(default_factory=lambda: [\"time\"])\n",
    "    variables: List = field(default_factory=lambda: [\"sossheig\"])\n",
    "    coarsen: Dict = field(default_factory=lambda: {\"lon\": 2, \"lat\": 2})\n",
    "    resample: str = \"1D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f1ee9-07d7-4d76-82b8-69453a87e036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "select = {\"time\": slice(\"2012-10-22\", \"2012-12-02\")}\n",
    "\n",
    "config_dm = OmegaConf.structured(SSHDMEVAL())\n",
    "\n",
    "dm_eval = hydra.utils.instantiate(\n",
    "    config_dm,\n",
    "    select=select,\n",
    "    spatial_transform=dm.spatial_transform,\n",
    "    temporal_transform=dm.temporal_transform,\n",
    ")\n",
    "\n",
    "dm_eval.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca3be9-35e9-40e8-beac-736a1cf4fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num Points: {len(dm_eval.ds_test):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d527f-181e-4ca1-8da1-a586246dd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xrda = dm_eval.load_xrds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a93cc-dff4-4c91-a121-e17a57ce69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.test_model(dm_eval.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1336da9-e5aa-4611-bffe-311e810c4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda[\"ssh_rff\"] = dm_eval.data_to_df(out).to_xarray().sossheig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd50f4b-d831-4197-aa6a-e596b3f2988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common_utils as cutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c1275-1ccb-4221-90c6-a59be09b4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rff = cutils.calculate_physical_quantities(xrda.ssh_rff)\n",
    "ds_natl60 = cutils.calculate_physical_quantities(xrda.sossheig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1039f4-249d-41f7-b6bd-487650c43ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cutils.plot_analysis_vars(\n",
    "    [\n",
    "        ds_natl60.isel(time=15),\n",
    "        ds_rff.isel(time=15),\n",
    "    ]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949195b9-6d5e-44da-addb-c1a596f0dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_natl60 = cutils.calculate_isotropic_psd(ds_natl60)\n",
    "ds_psd_rff = cutils.calculate_isotropic_psd(ds_rff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70dfd3a-e61c-4a24-836d-fb46c6021e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cutils.plot_analysis_psd_iso(\n",
    "    [\n",
    "        ds_psd_natl60,\n",
    "        ds_psd_rff,\n",
    "    ],\n",
    "    [\n",
    "        \"NATL60\",\n",
    "        \"RFE\",\n",
    "    ],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7e56a-7751-476e-9998-c44634d5fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_scores = cutils.calculate_isotropic_psd_score(ds_rff, ds_natl60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ec588-7873-48fb-8d48-17739a29127e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutils.plot_analysis_psd_iso_score([ds_psd_scores], [\"SIREN\"], [\"k\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10085ee5-e3f5-4290-90f4-e46b2e7f1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ivar in ds_psd_scores:\n",
    "    resolved_spatial_scale = ds_psd_scores[ivar].attrs[\"resolved_scale_space\"] / 1e3\n",
    "    print(f\"Wavelength [km]: {resolved_spatial_scale:.2f} [{ivar.upper()}]\")\n",
    "    print(f\"Wavelength [degree]: {resolved_spatial_scale/111:.2f} [{ivar.upper()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104d0f8-d5f9-4fbf-aba4-8d533b90096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_natl60 = cutils.calculate_spacetime_psd(ds_natl60)\n",
    "ds_psd_rff = cutils.calculate_spacetime_psd(ds_rff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f56f32-41b4-4845-bd12-b89f8f91bfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = cutils.plot_analysis_psd_spacetime(\n",
    "    [\n",
    "        ds_psd_natl60,\n",
    "        ds_psd_rff,\n",
    "    ],\n",
    "    [\n",
    "        \"NATL60\",\n",
    "        \"RFE\",\n",
    "    ],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63286b49-64ec-4b77-99ee-dc434345addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_psd_rff = cutils.calculate_spacetime_psd_score(ds_rff, ds_natl60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32456fe-a775-41db-88ab-175bb5307ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ivar in ds_psd_rff:\n",
    "    resolved_spatial_scale = ds_psd_rff[ivar].attrs[\"resolved_scale_space\"] / 1e3\n",
    "    print(f\"Resolved Scale [km]: {resolved_spatial_scale:.2f} [{ivar.upper()}]\")\n",
    "    resolved_temporal_scale = ds_psd_rff[ivar].attrs[\"resolved_scale_time\"]\n",
    "    print(f\"Resolved Scale [days]: {resolved_temporal_scale:.2f}  [{ivar.upper()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227097e-06bc-46d8-a013-cde71777f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cutils.plot_analysis_psd_spacetime_score([ds_psd_rff], [\"rff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d26a4-5bc4-4dae-994a-cbd1788a11ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-jejeqx]",
   "language": "python",
   "name": "conda-env-miniconda3-jejeqx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
